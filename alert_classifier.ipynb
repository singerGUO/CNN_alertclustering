{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alert_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkXj_USnKbtY",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "fe2f34e1-b853-4693-ddcd-71b7304d8f6f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-005dcc34-5b42-4e25-a839-65225577cd14\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-005dcc34-5b42-4e25-a839-65225577cd14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sys-log.csv to sys-log.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1eukDfLK-iY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a5c118d-d3e6-4501-f13e-9a93a9ca474f"
      },
      "source": [
        "# CNN for the logs classificaton\n",
        "import numpy\n",
        "import pandas\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "# utils functions define\n",
        "def str2numbers(strs):\n",
        "\tres = []\n",
        "\tfor str in strs:\n",
        "\t\twArr = []\n",
        "\t\t#split by whitespace and /\n",
        "\t\twords = re.split(\"[\\s\\/]\",str)\n",
        "\t  \n",
        "\t\tfor word in words:\n",
        "\n",
        "\t\t\twArr.append(sum([ord(c) for c in word]))\n",
        "\t\tres.append(wArr)\n",
        "\treturn res\n",
        "\n",
        "\t\n",
        "\t\n",
        "def predictions2className(classes,predictions):\n",
        "\tres = []\n",
        "\tfor prediction in predictions:\n",
        "\t\tindex = numpy.argmax(prediction)\n",
        "\t\tres.append(classes[index])\n",
        "\treturn res\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "dataframe = pandas.read_csv('sys-log.csv', sep='---', engine='python')\n",
        "\n",
        "dataset = dataframe.values\n",
        "numpy.random.shuffle(dataset)\n",
        "#test log length 85\n",
        "X_str = dataset[:,0]\n",
        "\n",
        "#label length 85\n",
        "y_str = dataset[:,1]\n",
        "\n",
        "train_size = int(len(X_str) * 0.8)\n",
        "test_size = len(X_str) - train_size\n",
        "#sum of unicode of each word\n",
        "X_num = str2numbers(X_str)\n",
        "\n",
        "X_train = X_num[:train_size]\n",
        "X_test = X_num[train_size:]\n",
        "#unique array, index to construct back to input array \n",
        "classes, y_num = numpy.unique(y_str, return_inverse=True)\n",
        "\n",
        "#(85,17) \n",
        "y_oneHot = np_utils.to_categorical(y_num)\n",
        "\n",
        "(68,17)\n",
        "y_train = y_oneHot[:train_size]\n",
        "#(17,17)\n",
        "y_test = y_oneHot[train_size:]\n",
        "# pad dataset to a maximum review length in words\n",
        "max_words = 100\n",
        "#(68,100)\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "#(17,100)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "# create the model\n",
        "top_words = 1000000\n",
        "#classify into 17\n",
        "outputs = len(classes)\n",
        "\"\"\"\n",
        "选择模型\n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "\"\"\"\n",
        "构建网络层\n",
        "\"\"\"\n",
        "#词嵌入 \n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "\n",
        "model.add(Convolution1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(outputs, activation='softmax'))\n",
        "\n",
        "\"\"\"\n",
        "编译\n",
        "\"\"\"\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=1, verbose=1)\n",
        "# Final evaluation of the model\n",
        "\n",
        "'''\n",
        "输出\n",
        "'''\n",
        "#loss and accuracy\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "#(17,17)\n",
        "predictions = model.predict(X_test, verbose=0)\n",
        "\n",
        "result = predictions2className(classes, predictions)\n",
        "print (\"############## Test logs: \",X_str[train_size:])\n",
        "print (\"############## Log types: \",y_str[train_size:])\n",
        "print (\"############## Prediction types: \",result)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 32)           32000000  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 100, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 50, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 250)               400250    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 17)                4267      \n",
            "=================================================================\n",
            "Total params: 32,407,621\n",
            "Trainable params: 32,407,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "68/68 [==============================] - 20s 291ms/step - loss: 2.8540 - accuracy: 0.0735 - val_loss: 2.8155 - val_accuracy: 0.1176\n",
            "Epoch 2/30\n",
            "68/68 [==============================] - 20s 290ms/step - loss: 2.6852 - accuracy: 0.4412 - val_loss: 2.6964 - val_accuracy: 0.0588\n",
            "Epoch 3/30\n",
            "68/68 [==============================] - 20s 291ms/step - loss: 2.0823 - accuracy: 0.4706 - val_loss: 2.0090 - val_accuracy: 0.4118\n",
            "Epoch 4/30\n",
            "68/68 [==============================] - 20s 290ms/step - loss: 1.1057 - accuracy: 0.7500 - val_loss: 1.0419 - val_accuracy: 0.5294\n",
            "Epoch 5/30\n",
            "68/68 [==============================] - 20s 290ms/step - loss: 0.4584 - accuracy: 0.9265 - val_loss: 0.5102 - val_accuracy: 0.9412\n",
            "Epoch 6/30\n",
            "68/68 [==============================] - 20s 289ms/step - loss: 0.2486 - accuracy: 0.9412 - val_loss: 0.4702 - val_accuracy: 0.8824\n",
            "Epoch 7/30\n",
            "68/68 [==============================] - 20s 289ms/step - loss: 0.0915 - accuracy: 0.9853 - val_loss: 0.3252 - val_accuracy: 0.9412\n",
            "Epoch 8/30\n",
            "68/68 [==============================] - 20s 288ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9412\n",
            "Epoch 9/30\n",
            "68/68 [==============================] - 20s 287ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9412\n",
            "Epoch 10/30\n",
            "68/68 [==============================] - 20s 288ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9412\n",
            "Epoch 11/30\n",
            "68/68 [==============================] - 20s 289ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9412\n",
            "Epoch 12/30\n",
            "68/68 [==============================] - 19s 286ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 0.9412\n",
            "Epoch 13/30\n",
            "68/68 [==============================] - 19s 287ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9412\n",
            "Epoch 14/30\n",
            "68/68 [==============================] - 19s 286ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9412\n",
            "Epoch 15/30\n",
            "68/68 [==============================] - 20s 287ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9412\n",
            "Epoch 16/30\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.9412\n",
            "Epoch 17/30\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9412\n",
            "Epoch 18/30\n",
            "68/68 [==============================] - 19s 285ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9412\n",
            "Epoch 19/30\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9412\n",
            "Epoch 20/30\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9412\n",
            "Epoch 21/30\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9412\n",
            "Epoch 22/30\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9412\n",
            "Epoch 23/30\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9412\n",
            "Epoch 24/30\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 9.5467e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9412\n",
            "Epoch 25/30\n",
            "68/68 [==============================] - 19s 283ms/step - loss: 8.4734e-04 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9412\n",
            "Epoch 26/30\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 7.6416e-04 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9412\n",
            "Epoch 27/30\n",
            "68/68 [==============================] - 19s 284ms/step - loss: 6.9641e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9412\n",
            "Epoch 28/30\n",
            "68/68 [==============================] - 19s 282ms/step - loss: 6.2978e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9412\n",
            "Epoch 29/30\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 5.7592e-04 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9412\n",
            "Epoch 30/30\n",
            "68/68 [==============================] - 19s 281ms/step - loss: 5.2408e-04 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9412\n",
            "Accuracy: 94.12%\n",
            "############## Test logs:  ['Mar 29 2004 09:55:23: %PIX-6-302005: Built UDP connection for faddr 193.192.160.244/3053 gaddr 10.0.0.187/53 laddr 192.168.0.2/53'\n",
            " '64.242.88.10 - - [07/Mar/2004:16:20:55 -0800] \"GET /twiki/bin/view/Main/DCCAndPostFix HTTP/1.1\" 200 5253'\n",
            " 'Sun, 2004-03-28 15:31:39 - TCP packet - Source:80.5.99.100,4662 ,WAN - Destination:217.224.147.21,4788 ,LAN [Drop] - [TCP preconnect traffic dropped]'\n",
            " 'Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Zip 1.08'\n",
            " '(II) PCI: 00:1d:1: chip 8086,24c4 card 174b,174b rev 02 class 0c,03,00 hdr 00'\n",
            " 'Mar 16 00:01:28 evita postfix/smtpd[1713]: EA11834022: client=camomile.cloud9.net[168.100.1.3]'\n",
            " 'Sun, 2004-03-28 15:36:10 - TCP packet - Source:140.112.243.228,5442 ,WAN - Destination:217.224.147.21,3283 ,LAN [Drop] - [TCP preconnect traffic dropped]'\n",
            " '64.242.88.10 - - [07/Mar/2004:16:10:02 -0800] \"GET /mailman/listinfo/hsdivision HTTP/1.1\" 200 6291'\n",
            " '[Sun Mar 7 05:39:40 2004] up2date Opening rpmdb in /var/lib/rpm/ with option 0'\n",
            " '(II) PCI: 00:00:0: chip 8086,2560 card 174b,174b rev 03 class 06,00,00 hdr 00'\n",
            " 'Mar 12 12:20:00 server2 /USR/SBIN/CRON[6837]: (root) CMD ( /usr/lib/sa/sa1 )'\n",
            " 'Mar 6 19:01:12 avas dccd[13284]: no incoming flood connection from dcc1.example.no, server-ID XXXX'\n",
            " 'Mar 12 09:27:20 server5 syslog: su : - ttyp1 user-informix'\n",
            " '[13:35:15] [13:35:15] Scanning for directory /usr/lib/.bkit-... [13:35:15] OK. Not found.'\n",
            " 'Mar 12 08:24:51 server6 sshd[24742]: Accepted password for netscape from 111.222.333.444 port 1420 ssh2'\n",
            " '[13:35:15] [13:35:15] Scanning for directory /tmp/.bkp... [13:35:15] OK. Not found.'\n",
            " 'Feb 2 09:00:14 avas.example.com amavisd[11568]: Module Archive::Tar 1.07']\n",
            "############## Log types:  ['Cisco PIX' 'Apache' 'NetGear FWG114P' 'Amavis-New' 'X Free 86' 'Postfix'\n",
            " 'NetGear FWG114P' 'Apache' 'Up 2 Date' 'X Free 86' 'SuSE SLES 8'\n",
            " 'Distributed Checksum Clearinghouse Server' 'HP-UX B.10.20' 'RK Hunter'\n",
            " 'HP UX B.11.00' 'RK Hunter' 'Amavis-New']\n",
            "############## Prediction types:  ['Cisco PIX', 'Apache', 'NetGear FWG114P', 'Amavis-New', 'X Free 86', 'Postfix', 'NetGear FWG114P', 'NetGear FWG114P', 'Up 2 Date', 'X Free 86', 'SuSE SLES 8', 'Distributed Checksum Clearinghouse Server', 'HP-UX B.10.20', 'RK Hunter', 'HP UX B.11.00', 'RK Hunter', 'Amavis-New']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBTrBpfGIQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8d55cc5f-d3fe-49d0-e0a1-1b903de55403"
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/new_model') "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/new_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKAyhXsVeDgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0be222e4-7528-401a-9021-202970dd9bb8"
      },
      "source": [
        "# my_model directory\n",
        "!ls saved_model\n",
        "\n",
        "# Contains an assets folder, saved_model.pb, and variables folder.\n",
        "!ls saved_model/new_model"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model\n",
            "assets\tsaved_model.pb\tvariables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm05ErFReIvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "8488cab3-e10e-474f-ea31-f98568d73488"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "new_model = tf.keras.models.load_model('saved_model/new_model')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 32)           32000000  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 100, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 50, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 250)               400250    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 17)                4267      \n",
            "=================================================================\n",
            "Total params: 32,407,621\n",
            "Trainable params: 32,407,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEUyCQxpelrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5042fc37-1519-4ab5-fa7f-503807d531f0"
      },
      "source": [
        "# Evaluate the restored model\n",
        "loss, acc = new_model.evaluate(X_test, y_test,verbose=0)\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (acc*100))\n",
        "\n",
        "print(new_model.predict(X_test).shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 94.12%\n",
            "(17, 17)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}